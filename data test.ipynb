{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import appropriate libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from numpy import nan as NA\n",
    "import datetime as datetime\n",
    "from models import db, Student, Floor, Collections, ShelfReading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New file path folder\n",
    "excel_file_path = 'file.xlsx'\n",
    "\n",
    "folder_name = os.path.splitext(os.path.basename(excel_file_path))[0]\n",
    "parent_directory = \"floor_3_collections\" \n",
    "\n",
    "folder_path = os.path.join(parent_directory, folder_name)\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read excel file of shelfreading data\n",
    "all_sheets = pd.read_excel('floor_3_SR.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sheets saved as CSV files in the folder: floor_3_collections\\file\n"
     ]
    }
   ],
   "source": [
    "#Save each sheet as a separate CSV file\n",
    "for sheet_name, df in all_sheets.items():\n",
    "    file_path = os.path.join(folder_path, f\"{sheet_name}.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"All sheets saved as CSV files in the folder: {folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_listing = pd.read_csv('Active CMR Student List - Sheet1.csv', header=None)\n",
    "student_listing[['Last Name', 'First Name']] = student_listing[0].str.split(',', expand=True)\n",
    "student_listing['First Name'] = student_listing['First Name'].str.strip()\n",
    "student_listing['Last Name'] = student_listing['Last Name'].str.strip()\n",
    "new_student_listing = student_listing.drop(columns=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = os.path.splitext(os.path.basename(excel_file_path))[0] + \"_edited\"\n",
    "parent_directory = \"new_floor_3\" \n",
    "folder_path = os.path.join(parent_directory, folder_name)\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_id(first_name, last_name):\n",
    "    student = Student.query.filter_by(student_fname=first_name, student_lname=last_name).first()\n",
    "    if student is None:\n",
    "        print(f\"Warning: Student with name {first_name} {last_name} not found!\")\n",
    "        return None\n",
    "    print(f\"Found student {first_name} {last_name} with ID {student.student_id}\")  # Add logging here\n",
    "    return student.student_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_sheet(df, new_student_listing):\n",
    "    default_datetime = pd.to_datetime('1900-01-01 00:00:00')\n",
    "\n",
    "    # Select relevant columns from the input dataframe\n",
    "    temp_df = df.iloc[:, [0, 1, 2, 3, 5, 6, 7]]\n",
    "    temp_df.columns = ['Name', 'date', 'start_time', 'end_time', 'shelves_completed', 'start_call', 'end_call']\n",
    "\n",
    "    # Remove rows with all NaN values and reset index\n",
    "    cleaned_temp_df = temp_df.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "    # Convert 'date' column to datetime64[ns] type\n",
    "    cleaned_temp_df['date'] = pd.to_datetime(cleaned_temp_df['date'], errors='coerce')\n",
    "\n",
    "    # Convert 'start_time' and 'end_time' to time format\n",
    "    cleaned_temp_df['start_time'] = pd.to_datetime(cleaned_temp_df['start_time'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "    cleaned_temp_df['end_time'] = pd.to_datetime(cleaned_temp_df['end_time'], format='%H:%M:%S', errors='coerce').dt.time\n",
    "\n",
    "    # Combine 'date' with 'start_time' and 'end_time' to form full datetime values\n",
    "    cleaned_temp_df['Start DateTime'] = cleaned_temp_df.apply(\n",
    "        lambda row: datetime.combine(row['date'].date(), row['start_time']) if pd.notnull(row['date']) and pd.notnull(row['start_time']) else default_datetime,\n",
    "        axis=1\n",
    "    )\n",
    "    cleaned_temp_df['End DateTime'] = cleaned_temp_df.apply(\n",
    "        lambda row: datetime.combine(row['date'].date(), row['end_time']) if pd.notnull(row['date']) and pd.notnull(row['end_time']) else default_datetime,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate 'Duration' as the difference between 'End DateTime' and 'Start DateTime'\n",
    "    cleaned_temp_df['Duration'] = cleaned_temp_df.apply(\n",
    "        lambda row: row['End DateTime'] - row['Start DateTime'] if pd.notnull(row['End DateTime']) and pd.notnull(row['Start DateTime']) else pd.NaT,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # If 'Duration' is a valid timedelta, convert it to hours, otherwise keep as NaT\n",
    "    cleaned_temp_df['Duration'] = cleaned_temp_df['Duration'].apply(\n",
    "        lambda x: round(x.total_seconds() / 3600, 2) if isinstance(x, pd.Timedelta) else \"Error, missing value\"\n",
    "    )\n",
    "\n",
    "    # Merge cleaned_temp_df with new_student_listing to get 'First Name' and 'Last Name'\n",
    "    merged_df = cleaned_temp_df.merge(new_student_listing[['First Name', 'Last Name']], \n",
    "                                      left_on='Name', right_on='First Name', how='left')\n",
    "\n",
    "    # Populate 'student_id' using get_student_id function\n",
    "    merged_df['student_id'] = merged_df.apply(\n",
    "        lambda row: get_student_id(row['First Name'], row['Last Name']), axis=1\n",
    "    )\n",
    "\n",
    "    # **Ensure these columns are properly created before dropping**\n",
    "    merged_df['temp_first_name'] = merged_df['First Name']\n",
    "    merged_df['temp_last_name'] = merged_df['Last Name']\n",
    "\n",
    "    # Now you can drop 'First Name' and 'Last Name' if necessary, but retain temp columns\n",
    "    merged_df = merged_df.drop(columns=['First Name', 'Last Name'])\n",
    "\n",
    "    # Continue with your existing logic...\n",
    "    # Reorder columns and clean up missing data\n",
    "    merged_df['Start DateTime'] = merged_df['Start DateTime'].fillna(default_datetime)\n",
    "    merged_df['End DateTime'] = merged_df['End DateTime'].fillna(default_datetime)\n",
    "    merged_df['date'] = merged_df['date'].fillna(default_datetime)\n",
    "    merged_df = merged_df.fillna(\"Missing\")\n",
    "\n",
    "    # Ensure columns are in the right order for return\n",
    "    merged_df = merged_df[['student_id', 'date', 'Start DateTime', 'End DateTime', \n",
    "                           'shelves_completed', 'start_call', 'end_call', 'Duration']]\n",
    "\n",
    "    # Remove rows with 'Missing' values in key columns\n",
    "    merged_df = merged_df[~((merged_df['date'] == 'Missing') | \n",
    "                            (merged_df['Start DateTime'] == 'Missing') | \n",
    "                            (merged_df['End DateTime'] == 'Missing') | \n",
    "                            (merged_df['student_id'] == 'Missing'))]\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_to_db(csv_file_path, excel_file_path):\n",
    "    print(\"Starting insert_data_to_db function\")  # Debug print to confirm the function is running\n",
    "    \n",
    "    floor_name = os.path.basename(excel_file_path).split('_')[1] \n",
    "    floor_id = int(floor_name)  \n",
    "\n",
    "    collection_name = os.path.basename(csv_file_path).split('.')[0] \n",
    "\n",
    "    collection = Collections.query.filter_by(collection=collection_name).first()\n",
    "    if collection is None:\n",
    "        print(f\"Warning: Collection with name {collection_name} not found!\")\n",
    "        collection_id = None\n",
    "    else:\n",
    "        collection_id = collection.collection_id\n",
    "\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    inserted_count = 0  # Counter for inserted records\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"Processing row: {row}\")  # Debug print for each row being processed\n",
    "        \n",
    "        if 'temp_first_name' in row and 'temp_last_name' in row:\n",
    "            student_id = get_student_id(row['temp_first_name'], row['temp_last_name'])\n",
    "        else:\n",
    "            print(\"Error: Missing first or last name in row\")\n",
    "            continue\n",
    "\n",
    "        if student_id is None:\n",
    "            print(f\"Error: Could not find student ID for {row['temp_first_name']} {row['temp_last_name']}\")\n",
    "            continue\n",
    "\n",
    "        row.drop(labels=['temp_first_name', 'temp_last_name'], inplace=True)\n",
    "\n",
    "        existing_record = ShelfReading.query.filter_by(\n",
    "            date=row['date'],\n",
    "            start_time=row['start_time'],\n",
    "            student_id=student_id\n",
    "        ).first()\n",
    "\n",
    "        if existing_record is None:\n",
    "            new_record = ShelfReading(\n",
    "                date=row['date'],\n",
    "                start_time=row['start_time'],\n",
    "                end_time=row['end_time'],\n",
    "                shelves_completed=row['shelves_completed'],\n",
    "                start_call=row['start_call'],\n",
    "                end_call=row['end_call'],\n",
    "                student_id=student_id,\n",
    "                floor_id=floor_id,\n",
    "                collection_id=collection_id\n",
    "            )\n",
    "            db.session.add(new_record)\n",
    "            try:\n",
    "                db.session.commit()\n",
    "            except Exception as e:\n",
    "                print(f\"Error committing to the database: {e}\")\n",
    "                db.session.rollback()  # Rollback in case of error\n",
    "            print(f\"Inserted new record for {row['temp_first_name']} {row['temp_last_name']} at floor {floor_id} and collection {collection_name}.\")\n",
    "            inserted_count += 1  # Increment count for successful insertions\n",
    "        else:\n",
    "            print(f\"Duplicate found for student {student_id} on {row['date']} at {row['start_time']} - Skipping insert.\")\n",
    "\n",
    "    print(f\"{inserted_count} records successfully inserted into the database.\")  # Ensure this line is reached\n",
    "    return f\"{inserted_count} records successfully inserted into the database.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_excel_file(excel_file_path):\n",
    "    # Read the Excel file\n",
    "    all_sheets = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "\n",
    "    # New file path folder based on Excel filename\n",
    "    folder_name = os.path.splitext(os.path.basename(excel_file_path))[0]\n",
    "    parent_directory = \"processed_files\"\n",
    "    folder_path = os.path.join(parent_directory, folder_name)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # Save each sheet as a separate CSV file\n",
    "    for sheet_name, df in all_sheets.items():\n",
    "        file_path = os.path.join(folder_path, f\"{sheet_name}.csv\")\n",
    "        df.to_csv(file_path, index=False)\n",
    "\n",
    "    print(f\"All sheets saved as CSV files in the folder: {folder_path}\")\n",
    "\n",
    "    # Load student data for merging\n",
    "    student_listing = pd.read_csv('Oogway-System/Active CMR Student List - Sheet1.csv', header=None)\n",
    "    student_listing[['Last Name', 'First Name']] = student_listing[0].str.split(',', expand=True)\n",
    "    student_listing['First Name'] = student_listing['First Name'].str.strip()\n",
    "    student_listing['Last Name'] = student_listing['Last Name'].str.strip()\n",
    "    new_student_listing = student_listing.drop(columns=[0])\n",
    "\n",
    "    # Folder to save edited files\n",
    "    edited_folder_name = folder_name + \"_edited\"\n",
    "    edited_folder_path = os.path.join(parent_directory, edited_folder_name)\n",
    "\n",
    "    if not os.path.exists(edited_folder_path):\n",
    "        os.makedirs(edited_folder_path)\n",
    "\n",
    "    # Process each sheet and save edited CSV files\n",
    "    edited_files_count = 0  # To count edited files\n",
    "    for sheet_name, df in all_sheets.items():\n",
    "        new_df = edit_sheet(df, new_student_listing)\n",
    "        file_path = os.path.join(edited_folder_path, f\"{sheet_name}_edited.csv\")\n",
    "        new_df.to_csv(file_path, index=False)\n",
    "        print(f\"Edited sheet '{sheet_name}' saved to: {file_path}\")\n",
    "        \n",
    "        # Insert data into the database\n",
    "        insert_data_to_db(file_path, excel_file_path)  # Pass excel file path to insert data\n",
    "        edited_files_count += 1\n",
    "\n",
    "    # Return a summary message\n",
    "    return f\"Processed {len(all_sheets)} sheets, saved {edited_files_count} edited files, and inserted data into the database.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sheet_name, df in all_sheets.items():\n",
    "#     new_df = edit_sheet(df, new_student_listing)\n",
    "#     print(new_df)\n",
    "    # file_path = os.path.join(folder_path, f\"{sheet_name}_edited.csv\")\n",
    "    # new_df2.to_csv(file_path, index=False)\n",
    "    \n",
    "    # print(f\"Edited sheet '{sheet_name}' saved to: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
